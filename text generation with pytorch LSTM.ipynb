{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e838be93-0e35-4b1b-a638-2bad15ce8659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1143k  100 1143k    0     0  1222k      0 --:--:-- --:--:-- --:--:-- 1229k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://gutenberg.org/files/1268/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5303cd1f-2612-4dc6-b05e-54e2d0b1d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length: 1130711\n",
      "Unique Characters: 85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open('1268-0.txt', 'r', encoding=\"utf8\") as f:\n",
    "    text = f.read()\n",
    "start_idx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_idx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)\n",
    "\n",
    "print(f\"Total length: {len(text)}\")\n",
    "\n",
    "print(f\"Unique Characters: {len(char_set)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19978b91-df65-42a8-8e88-97a2dd568f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS \n",
      "[48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
    "int2char = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32\n",
    ")\n",
    "\n",
    "print(text[:15])\n",
    "print(text_encoded[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053cd105-e7c1-42da-b98f-8615b8155c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yf/pdztvsqx3sx7h4vjwvlv67m00000gn/T/ipykernel_15777/555594384.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded) - chunk_size+1)]\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5f5605-3a37-4a74-9043-a3a3a47bf200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERIO'\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(repr(''.join(int2char[seq])))\n",
    "    print(repr(''.join(int2char[target])))\n",
    "    if i==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a833d78-0889-4192-b0f4-d8866757a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform Dataset into mini-batches\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size,\n",
    "                    shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a7664-0251-404f-920d-1e7b7dc83d3d",
   "metadata": {},
   "source": [
    "## Build a character-level RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94436dab-95ea-4bae-bb27-f06a2eb7b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8cc7376-96e0-4527-b0e7-3bb6dde7eae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(85, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(int2char)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9d82c9-2d73-4e0c-b8a0-50b20d0f3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f51adc-4d94-46f4-9774-b3198e70aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10_000\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cel = model(seq_batch[:, c], hidden, cell)\n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch} loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a8584c-f674-4fd1-b509-c7ee6e135e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "def sample(model, starting_str, len_generated_text=500, scale_factor=1.0):\n",
    "    encoded_input = torch.tensor(\n",
    "        [char2int[s] for s in starting_str]\n",
    "    )\n",
    "\n",
    "    encoded_input = torch.reshape(\n",
    "        encoded_input, (1, -1)\n",
    "    )\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(\n",
    "            encoded_input[:, c].view(1), hidden, cell\n",
    "        )\n",
    "\n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(\n",
    "            last_char.view(1), hidden, cell\n",
    "        )\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(int2char[last_char])\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8cb02b2-3ce1-4bfb-a66d-3e6a273c2b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The islandmiauts,\n",
      "our isents ofiaust o atteerly stuumes tially astanty forate, on unable. \n",
      "\n",
      "“It oilln, to roaten timear ssital our iste enen our fatilianes ofails. , howerars ofatine, sear antatin, sea, turalition.  spearetes fires ofual iten atmpous matinees, usilae stion, ous. seasu offialty onles secatte, of att hourpaty tien amiutes, woodme.\n",
      " soortea.  anstaitanly furoousa state ourn ofatts. --armety.\n",
      "\n",
      "\n",
      "\n",
      "“Ih anlesteen satity orate orooos, miatusa, antitus.  itselas.  halle, woolle, letaw, ancter elar \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "print(sample(model, starting_str=\"The island\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77cefcca-fa67-4ec9-a488-ce413ec1b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The islandmiatt ooous, antity oura tiouse speate ourate tin aloate, seare one, atitusa time, searitus, tear least oust ouste enty atimes ofures ofient our atiatus.  lootsiate our antits feorest isteer inles ofear oasts ourate time laste or ous tiluus tilia, sea.  also almoonsa antity furene ests satiousiate sea, furole, antity oures ofiants ofuries ofal atioust itates foroogen tione ourste story, antiounate stants ofures ofation ents ofures ofear antiousus firent ouranes ofar one offer antity anity, altit\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "print(sample(model, starting_str=\"The island\", scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe0b20-1053-4dd0-8a06-acfae0551147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
